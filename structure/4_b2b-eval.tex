\chapter{Evaluierung von Permissioned Blockchains für B2B-Anwendungen}
\label{cha:b2b-eval}

Die Blockchain-Technologie bringt diverse Probleme mit sich, welche je nach Anwendungszweck und Blockchaintyp verschieden große Auswirkungen haben. Für den \acs{B2B}-Bereich gilt es vor allem die Performance, Skalierbarkeit sowie Sicherheit in Verbindung mit den Konsensmechanismen zu analysieren. Je nach Ergebnis ist die Blockchain nur begrenzt für \acs{B2B}-Anwendungen geeignet. Das CAP-Theorem besagt, dass es in einem verteilten System nur möglich ist, zwei von den drei folgenden Eigenschaften zu gewährleisten: Konsistenz, Verfügbarkeit und Ausfalltoleranz. Bezogen auf die Blockchain wären dies: Dezentralisierung, Skalierbarkeit und Sicherheit \cite{SchererPerformanceScalabilityBlockchain2017}. Dies wird im Folgenden untersucht.

\section{Skalierbarkeit und Performance}
\label{sec:scalability-eval}
Die Skalierbarkeit eines Systems ist gegeben, wenn die Performance mit steigender Nutzerzahl zunimmt. Dies wird anhand von Public und Permissioned Blockchains analysiert. Für die Untersuchung der Performance werden die Daten zum Transaktionsdurchsatz von Visa (2000 \acs{TPS}) und \acs{IoT}-Anwendungen als Referenzwerte genutzt. So sagt Soto, dass für Smart Cities ein Durchsatz von über 1000 \acs{TPS} gebraucht wird \cite{AraujoSotoPerformanceevaluationscalable2017}. Vandikas et al. untersuchen eine \acs{IoT}-Plattform und stellen eine Performance von 2173 \acs{TPS} fest \cite{VandikasPerformanceEvaluationIoT2014}. 

\subsection{Public Blockchains}


\subsubsection{Bitcoin}

\begin{figure}[!htbp]
  \centering
    \includegraphics[width=0.65\textwidth,angle=0]{images/tps-comparison}
    \caption{Vergleich der \acs{TPS} bei verschiedenen Systemen \cite[S.~28]{SwanBlockchainblueprintnew2015}\cite{BitcoinTeamScalabilityBitcoinWiki}.}
    \label{fig:tps-comparison}
\end{figure} 

Das Bitcoin-Netzwerk erreicht aktuell einen maximalen Transaktionsdurchsatz von 7 \acs{TPS} (unterschiedlich je nach Größe der Transaktionen, variiert zwischen ungefähr 0,5 und 1,2 KB \cite{Bitcoin.comTeamBitcoinTransactionSize}), bei einer Blockgröße von 1 MB. Hingegen erreichen Visa und Twitter im Durchschnitt 2000 und 5000 \acs{TPS} (siehe Abb. \ref{fig:tps-comparison}) \cite[S.~28]{SwanBlockchainblueprintnew2015}. Hinzu kommt, dass bei Bitcoin ungefähr 170000 unbestätigte Transaktionen\footnote{Unbestätigte Transaktion: Eine Transaktion, welche noch nicht in einem Block vorkommt \cite[S.~13 ff.]{AntonopoulosMasteringbitcoin2015}.} bestehen \cite{BlockchainUnternehmenUnbestatigteTransaktionenBitcoin}. Berechnungen von Scherer zeigen, dass bei 11,8 Millionen Nutzern im Bitcoin-Netzwerk sowie einem Transaktionsdurchsatz von 4 \acs{TPS}, jeder Nutzer nur ca. 10 Transaktionen im Jahr senden kann \cite{SchererPerformanceScalabilityBlockchain2017}.

Der Transaktionsdurchsatz ist durch verschiedene Faktoren begrenzt. Hauptsächlich durch die limitierte Blockgröße von 1 MB und dem \acs{PoW}: Nur eine bestimmte Anzahl an Transaktionen passt in einen Block und nur alle 10 Minuten wird einer erstellt. Es gäbe also die Möglichkeit, die Blockgröße zu erhöhen, oder die Zeit für den \acs{PoW} zu verkürzen, indem die Schwierigkeit verringert wird. Es gibt jedoch diverse Nachteile, welche dadurch entstehen würden. Bei einer erhöhten Blockgröße würde es länger dauern, bis ein Block beim Propagieren durch das Netzwerk alle Nodes erreicht. Dies würde zu öfter auftretenden und längeren Forks führen und somit die Sicherheit des Netzwerks beeinträchtigen. Den gleichen Effekt hätte eine kürzere \acs{PoW} Zeit, da die Wahrscheinlichkeit höher ist, dass zwei Nodes zur ungefähr gleichen Zeit einen Block erstellen \cite{SchererPerformanceScalabilityBlockchain2017}\cite{EthereumTeamEthereumWhitePaper2017}\cite{SompolinskyAcceleratingBitcoinTransaction2013}. 

Entsteht ein Fork, probieren Nodes die längere und somit gültige Blockchain zu erschaffen. Gelingt dies, wird die kürzere Blockchain mit den nun sogenannten Stale Blocks verworfen. Die gesamte Rechenleistung, welche in die Stale Blocks geflossen ist, trägt nicht zur Sicherheit des Netzwerks bei. Dies lässt sich auch anhand der Abbildung \ref{fig:forking-risks} erläutern. Innerhalb der Blockchain bestehen durch mehrere Forks 5 Branches. Das bedeutet, dass die Rechenleistung des Netzwerks auf diese aufgespalten ist. Es wird davon ausgegangen, dass 20 \% der Rechenleistung in den obersten Branch geflossen ist, welcher der längste ist. Die restlichen 4 Branches erhalten je 10 \% der Rechenleistung. Wenn nun ein Angreifer mit 40 \% der Rechenleistung probiert, eine eigene Blockchain zu erstellen, gelingt ihm dies, da er schneller die längere Blockchain erstellen kann \cite{SompolinskyAcceleratingBitcoinTransaction2013}. Zusammenfassend lässt sich sagen, dass ein Angreifer weniger als 51 \% der Rechenleistung für einen Angriff benötigt, wenn genügend Forks bestehen \cite{Buterin12secondBlockTime2014}. 

\begin{figure}[!htbp]
  \centering
    \includegraphics[width=0.8\textwidth,angle=0]{images/forking-risks}
     \caption{Auswahl der gültigen Blockchain. Bei Bitcoin die längere. Bei Ethereum die mit der meisten erbrachten Arbeit, unter Einberechnung der Stale Blocks (Uncles) \cite{SompolinskyAcceleratingBitcoinTransaction2013}.}
    \label{fig:forking-risks}
\end{figure} 

Ein weiteres Problem der Forks ist, dass Miner keine Belohnung für die Arbeit an verworfenen Blöcken erhalten. Dadurch kann es zur Zentralisierung durch wachsende Mining Pools kommen. Dies wird an folgendem Beispiel ersichtlich: Ein Mining Pool A besitzt 30 \% der Rechenleistung, ein Mining Pool B 10 \%. In dem genannten Beispiel würde Mining Pool A in 70 \% aller Fälle einen Stale Block erzeugen und B in 90 \% aller Fälle. Kein Miner würde dem Mining Pool B beitreten, da die Wahrscheinlichkeit geringer ist, dass B gültige Blöcke erschafft. A hingegen würde immer mehr Miner und somit mehr Rechenleistung erhalten \cite{EthereumTeamEthereumWhitePaper2017}.

An dieser Stelle sollte auch darauf hingewiesen werden, dass schnellere Blockerstellungszeiten nicht zwingend zu schnelleren Transaktionsbetätigungen führen. Transaktionen werden zwar schneller in Blöcken aufgenommen, aber es muss auf mehr Nachfolger gewartet werden, um sicher zu gehen, dass die Transaktion nicht in einem Fork vorkommt \cite{SchererPerformanceScalabilityBlockchain2017}.

\subsection{Ethereum}

\paragraph{Bessere Performance durch GHOST}
Das Ethereum Netzwerk nutzt das sogenannte \acs{GHOST}-Protokoll und erreicht damit einen Transaktionsdurchsatz von 15 \acs{TPS}, bei einer durchschnittlichen Zeit von 15 Sekunden, um den \acs{PoW} zu erbringen. Dieses löst die Probleme des Forkings und der Benachteiligung von Minern. Ersteres wird dadurch gelöst, dass Stale Blocks in die Berechnung der gültigen Blockchain einfließen. Anders als bei Bitcoin, wo lediglich die Blöcke der längeren Chain und deren Nachfolger eine Rolle spielen. Die Stale Blocks werden in Ethereum als ``Uncles'' bezeichnet. Ein Uncle ist also ein in einem Fork bestehender Block, für welchen der \acs{PoW} zu spät erbracht wurde. Der \acs{PoW} für einen Block auf der gleichen Höhe wurde früher erbracht. So sind in Abbildung \ref{fig:forking-risks} die Blöcke 3C und 3E Uncles von 3D. Uncles sind nur gültig, wenn sie maximal eine bestimmte Anzahl an Generationen vom aktuellen Block in der gültigen Blockchain entfernt sind \cite{EthereumTeamEthereumWhitePaper2017}.

Die Bestimmung der gültigen Blockchain wird an der Abbildung \ref{fig:forking-risks} ersichtlich. In Ethereum ist die Blockchain gültig, für welche die meiste Arbeit aufgebracht wurde, unter Einbeziehung der Uncles. Das führt dazu, dass der Branch mit den meisten Uncles bestehen bleibt. Dies bedeutet letztendlich, dass die gesamte Rechenleistung das Netzwerk absichert, auch wenn sich diese auf die Branches aufteilt. Ein Angreifer braucht somit weiterhin 51 \% der Rechenleistung um einen Angriff auszuführen. Uncles sind nur gültig sind, wenn sie maximal eine bestimmte Anzahl an Generationen vom aktuellen Block in der gültigen Blockchain entfernt sind \cite{EthereumTeamEthereumWhitePaper2017} \cite{SompolinskyAcceleratingBitcoinTransaction2013}.

Damit ist allerdings noch nicht das Problem der Zentralisierung durch Mining Pools gelöst. Es besteht weiterhin keine Motivation für Miner, Uncles zu minen. Deswegen ist das \acs{GHOST}-Protokoll in Ethereum so erweitert, dass Miner Ether\footnote{Ether: Kryptowährung von Ethereum \cite{EthereumTeamEthereumWhitePaper2017}.} als Belohnung für das Erstellen von Uncles erhalten (allerdings weniger als bei vollwertigen Blöcken). Somit besteht eine größere Motivation, kleineren Mining Pools beizutreten \cite{EthereumTeamEthereumWhitePaper2017}. An dieser Stelle sollte auch erwähnt werden, dass Miner entscheiden können, an welchem Branch sie arbeiten \cite{ZhengBlockchainChallengesOpportunities2017}. 

Während Ethereum die Probleme löst, welche durch Forks entstehen, ist der Transaktionsdurchsatz trotzdem limitiert. Die Blockgröße muss klein genug bleiben, damit das Propagieren im Netzwerk effizient bleibt \cite{SchererPerformanceScalabilityBlockchain2017}. Ansonsten würden Miner unter Umständen so benachteiligt werden, dass sie nur selten bis gar nicht den aktuellen Block der gültigen Blockchain übermittelt bekommen würden. Dies wiederum würde dazu führen, dass sie nur Uncles minen und damit nie die volle Belohnung erhalten können. Hinzu kommt, dass Uncles nur gültig sind, wenn sie maximal eine bestimmte Anzahl an Generationen vom aktuellen Block in der gültigen Blockchain entfernt sind. Dadurch haben Miner eine größere Motivation ehrlich zu bleiben, da sie nicht ohne Nachteile an der Blockchain eines Angreifers arbeiten könnten \cite{EthereumTeamEthereumWhitePaper2017}.

\paragraph{Schlechtere Performance durch Smart Contracts}
Ethereum löst die Probleme von häufig auftretenden Forks und erlaubt so einen höheren Transaktionsdurchsatz sowie schnellere Transaktionsbestätigungszeiten. Weitere Probleme entstehen jedoch, wenn eine Blockchain nicht nur Geldtransfertransaktionen verarbeitet. Ethereum erlaubt das Speichern und Ausführen von eigenem Code durch Smart Contracts. Dadurch steigt die Komplexität der auszuführenden Transaktionen: Die entstehenden größeren Blöcke benötigen eine längere Propagationszeit und die Performance des Netzwerks nimmt ab, da die Daten schwieriger zu verarbeiten sind. So muss jede Node alle Transaktionen verifizieren, Smart-Contract-Code ausführen und die Ergebnisse speichern \cite{SchererPerformanceScalabilityBlockchain2017}. 

In Ethereum werden Transaktionen sequentiell bei allen Nodes ausgeführt. Dazu gehört das Ausführen von Smart-Contract-Code sowie das Verifizieren der Ergebnisse. Nur so können in Konflikt stehende Transaktionen, wie zum Beispiel beim Double-Spend, erkannt werden. Eine Parallelausführung ist nicht möglich. Dies verschlechtert letztendlich die Performance des Netzwerks, da es länger dauert Transaktionen auszuführen \cite{SchererPerformanceScalabilityBlockchain2017}. Dies wird auch durch ein Beispiel klar. Ein Angreifer kann DoS-Angriffe ausführen, indem er komplex auszuführende Smart Contracts schreibt. Dessen Ausführung bei jeder Node führt dazu, dass keine anderen Operationen ausgeführt werden können. Ethereum löst dieses Problem, indem der Transaktionssender für jeden Berechnungsschritt eine Gebühr zahlen muss. Dies funktioniert jedoch nur, wenn in der Blockchain-Anwendung eine Kryptowährung genutzt wird \cite{VukolicRethinkingPermissionedBlockchains2017}. 

Ebenfalls behauptet Vukolic, dass der Code der Smart Contracts nicht bei allen Nodes ausgeführt werden muss. Um Konsens zu erreichen, genügt es, dass alle Nodes den gleichen Stand der Daten erhalten. Deshalb könnte die Codeausführung nur von bestimmten Nodes ausgeführt werden. Das Problem dabei ist, dass eine genügend große Anzahl an vertrauenswürdigen Teilnehmer festgelegt werden muss \cite{VukolicRethinkingPermissionedBlockchains2017}. Damit geht allerdings auch das vertrauenslose Modell der Blockchain verloren.

Letztendlich lässt sich sagen, dass Public Blockchains nicht skalieren. Es ist ein maximaler Transaktionsdurchsatz gegeben, welcher mit einer höheren Anzahl an Peers und Nutzern gleich bleibt. Um dies zu lösen, müssen schnellere Blockpropagationszeiten, geringere Transaktionsgrößen und/oder bessere Transaktionsverarbeitung realisiert werden \cite{SchererPerformanceScalabilityBlockchain2017}. Bei Betrachtung des CAP-Theorem wird ersichtlich, dass nur die Eigenschaften Dezentralisierung und Sicherheit gegeben sind. Es ist jedoch zu bedenken, dass viele Probleme der Performance und Skalierbarkeit aufgrund des genutzten Konsensmechanismus bestehen. Auch wenn es teilweise Lösungsvorschläge für diese gibt, genügen sie bisher nicht. Deshalb gilt es, die Limitationen von Permissioned Blockchains sowie alternative Konsensmechanismen für diese zu analysieren.

%MinPermissioned: Introduces a concept for better throughput, but it is not tested (??)
%S.1-6 LiScalable: Introducing a concept with sattelite chains

\subsection{Permissioned Blockchains}
Permissioned Blockchains werden eingesetzt, wenn nur ausgewählte Teilnehmer an der Blockchain teilnehmen sollen. So gibt es beispielsweise auch eine verwaltende Instanz, welche u. a. die ersten berechtigten Teilnehmer bestimmt und die Netzwerkkonfiguration vornimmt. Dadurch entsteht eine stärkere Zentralisierung als bei Public Blockchains. Bezogen auf das CAP-Theorem, müssten sich dadurch die Sicherheit und/oder Skalierbarkeit verbessern. Dies führt allerdings auch dazu, dass ein größeres Maß an Vertrauen zwischen den Teilnehmern gegeben sein muss. Dies wird zum Teil dadurch sichergestellt, dass jeder Teilnehmer die Rechte zur Teilnahme am Netzwerk erhalten hat und die Identitäten dieser bekannt sind. Durch letztere ist nachverfolgbar, welche Teilnehmer welche Transaktionen ausführen \cite{SchererPerformanceScalabilityBlockchain2017}.

Scherer behauptet, dass das größere Vertrauen es erlaubt, den Nodes verschiedene Aufgaben zuzuteilen. Dies beschreibt er am Beispiel von Hyperledger Fabric (im Folgenden nur noch Fabric genannt), einer Permissioned-Blockchain. In dieser gibt es Peer und Ordering Nodes. Erstere simulieren das Ausführen der Transaktionen und der damit verbundenen Datenänderungen. Letztere bestimmen die Reihenfolge der auszuführenden Transaktionen in den Blöcken. Peer Nodes führen die bereits simulierten Transaktionen nacheinander aus und erkennen Konflikte in den Transaktionen (genauer im Kapitel \ref{sec:hyperledger-fabric-composer} erklärt). Die Ordering Nodes sind also letztendlich für den Konsens verantwortlich. In Gegensatz zu Ethereum können Peer Nodes so parallel Transaktionen verarbeiten. Sie müssen sich nicht um eventuelle Konflikte oder die Reihenfolge der Transaktionen kümmern. Letztendlich würde die Performance (im Bezug auf die Transaktionsverarbeitung), von der Hardware der Peers und der Anzahl dieser abhängen \cite{SchererPerformanceScalabilityBlockchain2017}.

%TODO: Warum müssen die Endorser kommunizieren ?
Scherer führt ebenfalls Tests durch, um die Performance von Fabric zu analysieren. Dazu nutzt er eine frühe und unstabile Version 1.0. Das Netzwerk besteht aus einer Ordering und einer Peer Node. Es wird kein Konsensmechanismus genutzt. Die Anwendung selbst unterstützt die Zahlung mittels digitaler Assets (z. B. Tokens bzw. Coins) zwischen zwei Accounts. Dabei erreicht er einen maximalen Transaktionsdurchsatz von 350 \acs{TPS}. Dabei ist allerdings zu bedenken, dass der Test auf einer Maschine mit limitierten Ressourcen ausgeführt wird. Um einen maximalen Transaktionsdurchsatz zu erreichen, müssten mehrere leistungsstarke Computer für den Test eingesetzt werden. Scherer stellt ebenfalls fest, dass der Transaktionsdurchsatz abnimmt, je mehr Peers es gibt, welche Transaktionen bestätigen (Endorser-Peers). Dies liegt daran, dass diese Endorser untereinander kommunizieren müssen. Pro Node müssten O(n$^2$) Nachrichten gesendet werden, wobei n die Anzahl an Nodes ist. Scherer erklärt dies jedoch nicht genauer. Laut seinen vorherigen Angaben kommunizieren Endorser lediglich mit Clients und Ordering Nodes. Trotzdem steht letztendlich fest, dass mehr Nachrichten gesendet werden müssen, je mehr Endorser existieren (siehe Kapitel \ref{sec:hyperledger-flow}. Dadurch ist die Anzahl an effizient nutzbaren Endorsern beschränkt. So führt der Test mit einem Endorser zu einen Transaktionsdurchsatz von ca. 70 \acs{TPS}, während mit 14 Endorsern nur noch ca. 15 \acs{TPS} erreicht werden. Damit wäre die Anzahl an effizient nutzbaren Endorsern begrenzt. Scherer behauptet jedoch, dass Fabric mit rechenstarken Maschinen in der Theorie tausende \acs{TPS} unterstützt \cite{SchererPerformanceScalabilityBlockchain2017}.

Ein Paper von Pongnumkul et al. vergleicht die Leistung von Fabric mit Ethereum. Er nutzt dazu die stabile Version 0.6. Er führt die Tests ebenfalls mit nur einer Peer Node durch. Zur Ordering Node macht er keine Angabe. Die Anwendung ist die gleiche wie bei Scherer und es wird ebenfalls kein Konsensmechanismus genutzt. Pongnumkul stellt fest, dass die Performance von Fabric in allen Kriterien besser ist als bei Ethereum. So betrug die Zeit, bis eine Beispieltransaktion verarbeitet wurde 41 Sekunden. Ethereum hingegen benötigte 478 Sekunden. Tests zum maximalen Transaktionsdurchsatz haben ergeben, dass Ethereum 40 \acs{TPS} und Fabric 300 \acs{TPS} erreicht hat. Die dazugehörige Abbildung \ref{fig:tps-ethereum-vs-hyperledger} zeigt auch, dass die Unterschiede zwischen den beiden Systemen signifikanter sind, je mehr Transaktionen verarbeitet werden müssen \cite{PongnumkulPerformanceAnalysisPrivate2017}.

\begin{figure}[!htbp]
  \centering
    \includegraphics[width=0.8\textwidth,angle=0]{images/TPS-ethvshyp}
     \caption{Vergleich des Transaktionsdurchsatzes von Ethereum und Fabric \cite{PongnumkulPerformanceAnalysisPrivate2017}.}
    \label{fig:tps-ethereum-vs-hyperledger}
\end{figure} 

Bei beiden Tests ist zu bedenken, dass sie mit nicht aktuellen Versionen von Fabric ausgeführt wurden. Mittlerweile gibt es eine stabile Version 1.0 sowie eine Preview von Version 1.1.0 \cite{HyperledgerFabricTeamHyperledgerFabricReleases2018}. Es ist also möglich, dass die Performance sich mittlerweile verbessert hat.

Letztendlich lässt sich sagen, dass Permissioned Blockchains, in Bezug auf Transaktionsverarbeitung, eine bessere Performance erzielen als Public Blockchains. Ebenfalls lässt sich diese über höhere Rechenleistung verbessern. Skalierbarkeit ist trotzdem nicht gegeben, da die Performance abnimmt, je mehr Nodes untereinander kommunizieren müssen. Dies wurde allerdings noch nicht unter der Nutzung verschiedener Konsensmechanismen betrachtet. Weiterhin muss das CAP-Theorem noch auf die Sicherheit untersucht werden. Deshalb erfolgt im nächsten Kapitel die Analyse der Skalierbarkeit und Sicherheit von Konsensmechanismen.

\section{Konsensmechanismen}
\label{sec:eval-konsens}
Das Erreichen von Konsens in einer Blockchain, ist eine Abwandlung des Byzantine Generals Problem. In diesem gibt es Generäle, welche Armeen kommandieren, welche eine Stadt umzingeln. Ein Angriff auf die Stadt ist nur erfolgreich, wenn alle Armeen gleichzeitig angreifen. Die Generäle müssen untereinander kommunizieren und Konsens darüber herstellen, ob ein Angriff erfolgen soll. Allerdings gibt es Verräter unter ihnen. Es handelt sich also um ein vertrauensloses Umfeld. Genau so kann es in einer Blockchain zu den sogenannten Byzantine Faults kommen, wenn nicht vertrauenswürdige Nodes Daten manipulieren können. Deshalb müssen verteilte Systeme \acl{BFT} (\acs{BFT}) herstellen, um eine gewisse Anzahl an nicht vertrauenswürdigen Teilnehmern zu tolerieren. Dies geschieht in Blockchains über die Konsensmechanismen \cite{ZhengBlockchainChallengesOpportunities2017}.

Eine Blockchain, welche den \acs{PoW} als Konsensmechanismus nutzt, ist nicht skalierbar. Ebenfalls würde dieser in Netzwerken mit wenig Teilnehmern die Sicherheit beeinträchtigen, da ein Teilnehmer einfacher 51 \% der Rechenleistung erreichen kann. Für Permissioned Blockchains muss also ein Konsensmechanismus gefunden werden, welcher Skalierbarkeit und Sicherheit herstellt. Scherer behauptet, dass aufgrund des höheren Vertrauens in Permissioned Blockchains, ein Konsensmechanismus genutzt werden kann, welcher Vertrauen in geringerem Maße als der \acs{PoW} herstellt. Somit könnten Skalierbarkeit und Sicherheit hergestellt werden \cite{SchererPerformanceScalabilityBlockchain2017}. Im Folgenden werden verschiedene Konsensmechanismen verschiedener Blockchain-Technologien miteinander verglichen.

\subsection{Proof-of-Stake}
Beim \acs{PoS} hängt die Wahrscheinlichkeit, einen Block zu minen, von der Menge des Eigentums (z. B. Kryptowährung) eines Nutzers ab. Je mehr Bitcoins dieser beispielsweise besitzt, desto höher ist die Wahrscheinlichkeit, für das Mining ausgewählt zu werden. Ähnlich wie beim \acs{PoW} könnte ein Teilnehmer mit 51 \% aller Bitcoins das Netzwerk angreifen, da er die längere Blockchain erstellen kann. Aber selbst wenn es ein Teilnehmer schafft, 51 \% der Bitcoins zu besitzen, hätte er keine Motivation einen Angriff auszuführen. Denn dieser würde den Kurs von Bitcoin senken, womit der Miner sich selbst schaden würde \cite{ZhengBlockchainChallengesOpportunities2017}. Da der PoS hauptsächlich nur bei Kryptowährungen genutzt werden kann, ist er für Permissioned Blockchains uninteressant.

\subsection{Proof-of-Elapsed-Time}
Der \acs{PoET} wird in Intels Blockchain-Technologie Hyperledger Sawtooth genutzt. Die grundlegende Idee ist, dass eine Node eine zufällige Zeit generiert, welche Sie warten muss, um einen Block zu erstellen. Um sicherzustellen, dass die generierte Zeit nicht verfälscht wurde, wird Trusted Computing \footnote{Trusted Computing: Hardware, welche sicherstellt, dass Software sich wie erwartet verhält \cite{MitchellTrustedComputing2005}.} genutzt. So stellen Intels Software Guard Extensions (SGX) sicher, dass Code während der Ausführung nicht modifiziert werden kann. Eine Node muss also über solchen unmodifizierbaren Code eine Zeit generieren. Weiterhin erfolgen statistische Tests, um zu verhindern, dass eine Node Blöcke zu schnell und somit zu oft erstellt. Letztendlich ist die Blockerstellung damit fair verteilt und kein Teilnehmer kann die Blockchain kontrollieren. Im Prinzip funktioniert der Mechanismus wie der \acs{PoW}. Dort wird eine Wartezeit durch das Finden eines Hashes sichergestellt, während dies beim \acs{PoET} durch die Hardware geschieht. Die Performance ist sichergesteltt, da es keine rechenintensiven Aufgaben gibt. Es ist jedoch zu bedenken, dass es bisher wenige Analysen zu der Sicherheit des \acs{PoET} gibt. Ein Paper von Chen et al. stellt fest, dass der Konsensmechanismus unter bestimmten Umständen unsicher ist, schlägt aber auch Lösungen dafür vor. Ebenfalls kommt hinzu, dass der Hardware von Intel für das Trusted Computing vertraut werden muss \cite{ChenSecurityAnalysisProofofElapsedTime2017}.

\subsection{Diversity Mining Consensus}
Der Diversity Mining Consensus ist ähnlich dem \acs{PoW}. In diesem ist der Block einer Node nur valide, wenn sie eine bestimmte Anzahl an vorherigen Blöcken nicht erstellt hat. Dies führt letztendlich dazu, dass eine Wartezeit für jede Node nicht durch das Finden eines Hashes (siehe \acs{PoW}) oder durch eine generierte Zeit (siehe \acs{PoET}) realisiert wird. Für den Mechanismus müssen alle Teilnehmer am Netzwerk bekannt sein. Auch hier kann es zu Forks kommen, wenn zwei Nodes zur ungefähr gleichen Zeit einen Block erstellen. Ebenfalls wird die entstehende längere Blockchain akzeptiert. Durch die Wartezeit wird sichergestellt, dass der Branch mit den meisten Minern die längere Blockchain erstellt. Die Gefahr bei diesem Konsensmechanismus ist, dass bösartige Miner sich zusammen tun können. Unter den richtigen Umständen erstellt der Zusammenschluss die meisten Blöcke und kann somit auch bei Forks eine längere Blockchain erstellen, um so Double-Spending-Angriffe auszuführen. Die Performance ist aufgrund des fehlenden Rechenaufwands sichergestellt \cite{GreenspanMultiChainPrivateBlockchain2015}\cite{CachinBlockchainConsensusProtocols2017}.

\subsection{QuorumChain}
Quorum ist ein Fork von Ethereum für Permissioned Blockchains. Dieser nutzt den Konsensmechanismus QuorumChain. Es gibt Voter und Block-Maker Nodes. Die Block-Maker schlagen Blöcke zum Erstellen vor und die Voter stimmen über diese ab. Um Forks zu verhindern, warten die Block-Maker eine zufällige Zeit und erstellen den Block. Die Voter validieren diesen und stimmen über ihn ab, indem Sie u. a. die Transaktionen ausführen und überprüfen, ob der vorherige Block genug Stimmen erhalten hat. Die Nodes hängen letztendlich den Block an ihre lokale Blockchain an, welcher einen bestimmten Schwellwert an Stimmen überschritten hat oder im Falle eines Forks die meisten Stimmen erhalten hat. Jedoch ist die Sicherheit des Mechanismus fragwürdig. Laut Cachin et al. soll es schon allein mit einem bösartigen Block-Maker zu Forks kommen, welche Double-Spending-Angriffe ermöglichen und die Zeit erhöhen, bis eine Transaktion nicht mehr verworfen werden kann. Quroum nutzt ebenfalls einen Konsensmechanismus basierend auf Raft. Auf diesen wird nicht genauer eingegangen, da er keine nicht vertrauenswürdigen Nodes toleriert, und damit unsicher ist \cite{CachinBlockchainConsensusProtocols2017}.

\subsection{Practical Byzantine Fault Tolerance}
Der \acs{PBFT} gehört zu der Familie der \acs{BFT}-Protokolle. Hier müssen ebenfalls alle Teilnehmer bekannt sein. Beim \acs{PBFT} wählen die Teilnehmer eine Leader-Node. Jede Runde schlägt diese einen neuen Block mit auszuführenden Transaktionen vor. Dieser wird an alle anderen Nodes weitergeleitet. Anschließend wird der Konsens hergestellt. \nicefrac{2}{3} der Nodes müssen dem im Block enthaltenen Transaktionen zustimmen, damit er erstellt wird. Erst dann werden die Transaktionen bei jedem Teilnehmer ausgeführt. Deshalb können bis zu \nicefrac{1}{3} der Nodes nicht vertrauenswürdig sein. Ein Angreifer müsste für einen Angriff die Kontrolle über \nicefrac{2}{3} der Nodes haben \cite{SukhwaniPerformanceModelingPBFT2017a}\cite{ZhengBlockchainChallengesOpportunities2017}. 

Vukolic behauptet, dass es \acs{BFT}-Protokolle gibt, welche einen Transaktionsdurchsatz von mehreren 10000 \acs{TPS} unterstützen. Die Performce dieser bezüglich der Anzahl an Nodes ist jedoch begrenzt. Dies liegt an dem Kommunikationsaufwand, welcher durch das Abstimmen über den Leader und die Transaktionen entsteht \cite{Vukolicquestscalableblockchain2015}. Croman erzielt bei seinen Tests mit dem \acs{PBFT}, bei 8 Nodes und 8192 auszuführenden Transaktionen, einen Transaktionsdurchsatz von 14000 \acs{TPS}. Weiterhin wird ersichtlich, wie die Performance mit der Anzahl an Nodes abnimmt. Mit 64 Nodes und 8192 auszuführenden Transaktionen wird ein Transaktionsdurchsatz von 4500 \acs{TPS} erreicht \cite{CromanScalingDecentralizedBlockchains2016}. Im Gegensatz zum \acs{PoW} besteht hier eine bessere Performance, welche jedoch mit steigender Nutzerzahl abnimmt \cite{Vukolicquestscalableblockchain2015}.

Ein weiterer Vorteil von \acs{BFT}-Protokollen ist, dass es Consensus Finality gibt. Das bedeutet, dass es nicht zu Forks kommen kann. Somit müssten Nutzer nach einer Transaktion nicht auf die Erstellung von nachfolgenden Blöcken warten, um sicher zu gehen, dass sie endgültig bestehen wird. Somit entfällt auch die Gefahr von Double-Spending-Angriffen \cite{Vukolicquestscalableblockchain2015}.

Die Angriffe, welche mit mehr als \nicefrac{1}{3} der Voting Power erfolgen können, sind die sogenannten Censorship Attacks. So könnten Nodes verhindern, dass neue Blöcke entstehen, indem sie ihre Stimme zurückhalten. Weiterhin könnten sie bestimmte Transaktionen zensieren, indem sie dafür stimmen, diese nicht in einen Block aufzunehmen \cite{TendermintTeamTendermintGithubRepository2018}.

\subsection{Tendermint}
Tendermint ist eine Abwandlung des \acs{PBFT}-Konsensmechanismus. Der größte Unterschied besteht darin, dass die Nodes, welche einen Block vorschlagen, in einem Round-Robin Verfahren ausgewählt werden. So gibt es in jeder Runde einen neue Leader-Node. Hinzu kommt, dass die Teilnehmer mit ihren Coins, welche die Voting Power bestimmen, abstimmen. Die Coins werden für eine bestimmte Zeit an eine Vote gebunden und damit für die weitere Nutzung gesperrt. Aufgrund der Asynchronität des Netzwerks kann es vorkommen, dass eine Node noch keine Information über einen bereits neu erstellten Block erhalten hat. Dies führt dazu, dass sie einen neuen Block auf der gleichen Höhe des bestehenden Blocks vorschlägt. Es kann dann zu einem Fork kommen, wenn beide Blöcke \nicefrac{2}{3} der Voting Power erhalten. Dies ist jedoch nur möglich, wenn mindestens \nicefrac{1}{3} der Voting Power bösartig genutzt wird, also doppelt abstimmt. Durch die an die Abstimmung gebundenen Coins kann jedoch eine Bestrafung erfolgen. So werden die gebundenen Coins einfach zerstört. Somit werden nicht vertrauenswürdige Nodes toleriert und Double-Spending verhindert \cite{KwonTendermintConsensusmining2014}\cite{BuchmanTendermintByzantineFault2016}. Es ist zu bedenken, dass der Mechanismus nur mit einer Kryptowährung im vollen Umfang funktioniert.

\subsection{Sonstige BFT-Konsensmechanismen}
Neben den bisher erwähnten \acs{BFT}-Konsensmechanismen gibt es noch diverse andere, welche das Prinzip des \acs{PBFT} mehr oder weniger abwandeln. So gibt es Symbiont und R3 Corda mit BFT-SMaRt, Iroha mit Sumeragi, Kadena mit ScalableBFT und Chain mit Federated Consensus \cite{CachinBlockchainConsensusProtocols2017}. Aufgrund der Vielfalt und des Detailreichtums dieser Konsensmechanismen, wird nicht genauer auf sie eingegangen. Es genügt die Prinzipien von \acs{BFT}-Protokollen anhand des \acs{PBFT} zu verstehen.

\section{Sonstige Einschränkungen}

\subsection{Private Transaktionen}
In Blockchains wie bei Bitcoin und Ethereum ist es nicht möglich, private Transaktionen auszuführen. Das bedeutet, alle Transaktionen sind für alle Teilnehmer sichtbar. Ist dies nicht erwünscht, werden Permissioned Blockchains genutzt. So soll beispielsweise eine Preisabsprache zwischen 2 Teilnehmern in der Blockchain dokumentiert werden, welche für andere nicht ersichtlich ist.

In Quorum wird dies realisiert, indem in einer Transaktion angegeben wird, welche Teilnehmer die Transaktion sehen dürfen. Diese wird anschließend verschlüsselt und kann nur von den angegebenen Teilnehmern entschlüsselt werden. Die Transaktion wird im Netzwerk verteilt und nur von den Teilhabern ausgeführt \cite{QuorumTeamTransactionProcessingQuorum2018}.

In Fabric werden private Transaktionen über Channels ermöglicht. Dabei ist jeder Channel eine eigene Blockchain, mit verschiedenen Teilnehmern. So würde es beispielsweise einen öffentlichen Channel geben, an welchem alle Teilnehmer der Permissioned Blockchain teilnehmen. Zusätzlich würde es private Channel geben, welche nur zwischen bestimmten Teilnehmern bestehen würden. Ein direkter Datenaustausch zwischen den Channeln ist nicht möglich \cite{SchererPerformanceScalabilityBlockchain2017}. 

Der Konsens bei privaten Transaktionen stellt ein Problem dar. In Quorum sind Teile der Transaktion verschlüsselt, wodurch diese nicht von allen Nodes verifiziert werden können. Die Verifizierung ist jedoch trotzdem anhand anderer Daten möglich (siehe \cite{QuorumTeamQuorumChainConsensus2018}). In Fabric wird der Konsens über Ordering Nodes hergestellt. Teilnehmer eines Channels könnten bereits bestehende Ordering Nodes nutzen, wodurch diese allerdings die privaten Transaktionen erhalten. Ebenfalls könnten für den Channel neue Ordering Nodes von jedem Teilnehmer erstellt werden. Mit nur 2 Teilnehmern wäre dies jedoch, je nach genutztem Konsensmechanismus, problematisch. So würde beispielsweise beim \acs{PoW} der Teilnehmer mit der höheren Rechenleistung die Kontrolle über die Blockchain haben. Zu dem Konsens bei privaten Transaktionen in Fabric konnten keine Quellen gefunden werden.
%S.2 WustYouNeedBlockchain: Tensio between Transparency and Privacy ?

\subsection{Datenmenge}
Ein noch nicht angesprochenes Problem der Blockchain ist die Datenredundanz im Bezug auf die Datenmenge. Da keine Daten in der Blockchain gelöscht werden können, wächst sie stetig an. So ist die Bitcoin-Blockchain im Moment 151 GB groß \cite{BlockchainUnternehmenBlockchainSizeBitcoin}. Größere Datenmengen werden schneller erreicht, wenn nicht nur Geldtransferaktionen bestehen.

Die Datenmenge stellt ein Problem dar, da Teilnehmer ab einem bestimmten Punkt eventuell nicht mehr bereit sind die Blockchain auf ihrer Node zu speichern. Dies würde zu weniger Minern und somit zu höherer Zentralisierung führen \cite{SchererPerformanceScalabilityBlockchain2017}.

\section{Zusammenfassung}
Die Skalierbarkeit von Public Blockchains stellt ein Problem für Anwendungen dar. Die Performance ändert sich mit wachsender Nutzerzahl zwar nicht \cite{SchererPerformanceScalabilityBlockchain2017}, ist aber trotzdem zu gering, um eine Vielzahl an Peers zu unterstützen. In Permissioned Blockchains ist das Gegenteil der Fall. Es besteht eine höhere Performance, welche jedoch mit der Anzahl an Peers abnimmt. Die Transaktionsverarbeitung von Fabric ist über Rechenleistung skalierbar. Allerdings verringert sich die Performance, je mehr Nodes untereinander kommunizieren müssen. Konsensmechanismen wie \acs{PBFT} unterstützten tausende von \acs{TPS} pro Sekunde. Der Transaktionsdurchsatz nimmt jedoch ebenfalls mit der Anzahl an Nodes ab. Zukünftige Analyse ist nötig, um festzustellen, in welchen Maße die Performance beeinflusst wird. Trotzdem kann die Aussage getroffen werden, dass auch Permissioned Blockchains nicht skalieren. Darauf basierende Anwendungen sind auf einen bestimmten Transaktionsdurchsatz bzw. auf eine bestimmte Anzahl an Nodes beschränkt. Der Transaktionsdurchsatz von Visa und \acs{IoT}-Anwendungen kann also nur unter den richtigen Voraussetzungen erreicht werden. Weiterhin bestätigt sich das CAP-Theorem. Lediglich Dezentralisierung und Sicherheit sind sichergestellt.

Blockchain-Implementationen wie Fabric und Quorum zeigen, dass private Transaktionen realisiert werden können. Bezüglich dieser ist jedoch unklar, wie effizient der Konsens umgesetzt werden kann. Für die redundante Datenhaltung und damit zusammenhängende Datenmenge, welche jeder Miner speichern muss, gibt es keine Lösung.





